{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b38caa93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "with zipfile.ZipFile(\"coco2017.zip\",\"r\") as zip_ref:\n",
    "    zip_ref.extractall(\"coco\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada0e8ff",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3a4fb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load annotation file\n",
    "with open('coco/annotations/instances_train2017.json', 'r') as f:\n",
    "    coco_data = json.load(f)\n",
    "\n",
    "# access relevant information\n",
    "images = coco_data['images']\n",
    "annotations = coco_data['annotations']\n",
    "categories = coco_data['categories']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc35d8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image path for train data\n",
    "image_dir = 'coco1/train2017/'\n",
    "image_paths = [image_dir + img['file_name'] for img in coco_data['images']]\n",
    "\n",
    "# dictionary to map category IDs to class indices\n",
    "category_id_to_class_index = {}\n",
    "for category in coco_data['categories']:\n",
    "    category_id_to_class_index[category['id']] = len(category_id_to_class_index)\n",
    "\n",
    "# to store preprocessed data\n",
    "preprocessed_images = []\n",
    "preprocessed_labels = []\n",
    "\n",
    "# input for YOLO - 416x416 \n",
    "target_size = (416, 416)\n",
    "\n",
    "for annotation in coco_data['annotations']:\n",
    "    image_id = annotation['image_id']\n",
    "\n",
    "    # check if image_id is within the valid range of indices\n",
    "    if 1 <= image_id <= len(coco_data['images']):\n",
    "        category_id = annotation['category_id']\n",
    "        bbox = annotation['bbox']\n",
    "\n",
    "        image_path = image_dir + coco_data['images'][image_id - 1]['file_name']\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # convert to RGB color space\n",
    "        image = cv2.resize(image, target_size)  # resize to the target size\n",
    "        image = image.astype(np.float32) / 255.0  # normalize pixel values \n",
    "        \n",
    "        # bounding box coordinates and class labels\n",
    "        x, y, width, height = bbox\n",
    "        x /= target_size[0]  \n",
    "        y /= target_size[1]  \n",
    "        width /= target_size[0]  \n",
    "        height /= target_size[1]  \n",
    "\n",
    "        class_index = category_id_to_class_index[category_id]\n",
    "\n",
    "        # store the preprocessed image and label\n",
    "        preprocessed_images.append(image)\n",
    "        preprocessed_labels.append([class_index, x, y, width, height])\n",
    "\n",
    "# convert the lists to numpy arrays\n",
    "preprocessed_images = np.array(preprocessed_images)\n",
    "preprocessed_labels = np.array(preprocessed_labels)\n",
    "\n",
    "## preprocessed_images: contains the preprocessed images (normalized and resized)\n",
    "## preprocessed_labels: contains the preprocessed labels (class index, bounding box coordinates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4f9eb9",
   "metadata": {},
   "source": [
    "### Model architecture "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f1355e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input shape and true boxes input\n",
    "\n",
    "IMAGE_H, IMAGE_W, CHANNELS = 416, 416, 3\n",
    "TRUE_BOX_BUFFER = 50\n",
    "GRID_H, GRID_W = 13, 13      # grid size\n",
    "BOX = 5                      # no. of anchor boxes\n",
    "ANCHORS = [0.57273, 0.677385, 1.87446, 2.06253, 3.33843, 5.47434, 7.88282, 3.52778, 9.77052, 9.16828]\n",
    "CLASS = 80                   # no. of classes\n",
    "NO_OBJECT_SCALE  = 1.0\n",
    "OBJECT_SCALE     = 5.0\n",
    "COORD_SCALE      = 1.0\n",
    "CLASS_SCALE      = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5126daa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image = Input(shape=(IMAGE_H, IMAGE_W, CHANNELS))\n",
    "true_boxes = Input(shape=(1, 1, 1, TRUE_BOX_BUFFER, 4))\n",
    "\n",
    "## implementation of the YOLO v2 model architecture\n",
    "\n",
    "# Layer 1\n",
    "x = Conv2D(32, (3,3), strides=(1,1), padding='same', name='conv_1', use_bias=False)(input_image)\n",
    "x = BatchNormalization(name='norm_1')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "# Layer 2\n",
    "x = Conv2D(64, (3,3), strides=(1,1), padding='same', name='conv_2', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_2')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "# Layer 3\n",
    "x = Conv2D(128, (3,3), strides=(1,1), padding='same', name='conv_3', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_3')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 4\n",
    "x = Conv2D(64, (1,1), strides=(1,1), padding='same', name='conv_4', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_4')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 5\n",
    "x = Conv2D(128, (3,3), strides=(1,1), padding='same', name='conv_5', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_5')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "# Layer 6\n",
    "x = Conv2D(256, (3,3), strides=(1,1), padding='same', name='conv_6', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_6')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 7\n",
    "x = Conv2D(128, (1,1), strides=(1,1), padding='same', name='conv_7', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_7')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 8\n",
    "x = Conv2D(256, (3,3), strides=(1,1), padding='same', name='conv_8', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_8')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "# Layer 9\n",
    "x = Conv2D(512, (3,3), strides=(1,1), padding='same', name='conv_9', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_9')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 10\n",
    "x = Conv2D(256, (1,1), strides=(1,1), padding='same', name='conv_10', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_10')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 11\n",
    "x = Conv2D(512, (3,3), strides=(1,1), padding='same', name='conv_11', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_11')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 12\n",
    "x = Conv2D(256, (1,1), strides=(1,1), padding='same', name='conv_12', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_12')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 13\n",
    "x = Conv2D(512, (3,3), strides=(1,1), padding='same', name='conv_13', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_13')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "skip_connection = x\n",
    "\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "# Layer 14\n",
    "x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_14', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_14')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 15\n",
    "x = Conv2D(512, (1,1), strides=(1,1), padding='same', name='conv_15', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_15')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 16\n",
    "x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_16', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_16')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 17\n",
    "x = Conv2D(512, (1,1), strides=(1,1), padding='same', name='conv_17', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_17')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 18\n",
    "x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_18', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_18')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 19\n",
    "x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_19', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_19')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 20\n",
    "x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_20', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_20')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 21\n",
    "skip_connection = Conv2D(64, (1,1), strides=(1,1), padding='same', name='conv_21', use_bias=False)(skip_connection)\n",
    "skip_connection = BatchNormalization(name='norm_21')(skip_connection)\n",
    "skip_connection = LeakyReLU(alpha=0.1)(skip_connection)\n",
    "skip_connection = Lambda(space_to_depth_x2)(skip_connection)\n",
    "\n",
    "x = concatenate([skip_connection, x])\n",
    "\n",
    "# Layer 22\n",
    "x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_22', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_22')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 23\n",
    "x = Conv2D(BOX * (4 + 1 + CLASS), (1,1), strides=(1,1), padding='same', name='conv_23')(x)\n",
    "output = Reshape((GRID_H, GRID_W, BOX, 4 + 1 + CLASS))(x)\n",
    "\n",
    "# Output layer\n",
    "output = Conv2D(BOX * (4 + 1 + CLASS), (1, 1), strides=(1, 1), padding='same', name='conv_23')(x)\n",
    "output = Reshape((GRID_H, GRID_W, BOX, 4 + 1 + CLASS))(output)\n",
    "\n",
    "output = Lambda(lambda args: args[0])([output, true_boxes])\n",
    "\n",
    "# final model\n",
    "model = Model([input_image, true_boxes], output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b3c07d",
   "metadata": {},
   "source": [
    "### Loss function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65720da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## loss function\n",
    "\n",
    "### Total loss =  Bounding box accuracy loss + Class probability accuracy loss + Confidence score loss \n",
    "### combination of localization, confidence, and classification losses\n",
    "\n",
    "def custom_loss(y_true, y_pred):\n",
    "    mask_shape = tf.shape(y_true)[:4]\n",
    "    \n",
    "    cell_x = tf.to_float(tf.reshape(tf.tile(tf.range(GRID_W), [GRID_H]), (1, GRID_H, GRID_W, 1, 1)))\n",
    "    cell_y = tf.transpose(cell_x, (0, 2, 1, 3, 4))\n",
    "\n",
    "    cell_grid = tf.tile(tf.concat([cell_x, cell_y], -1), [BATCH_SIZE, 1, 1, 5, 1])\n",
    "    \n",
    "    coord_mask = tf.zeros(mask_shape)\n",
    "    conf_mask = tf.zeros(mask_shape)\n",
    "    class_mask = tf.zeros(mask_shape)\n",
    "    \n",
    "    ## Bounding box predictions\n",
    "    \n",
    "    pred_box_xy = tf.sigmoid(y_pred[..., :2]) + cell_grid   ## x & y\n",
    "    \n",
    "    pred_box_wh = tf.exp(y_pred[..., 2:4]) * np.reshape(ANCHORS, [1, 1, 1, BOX, 2])  ## w & h\n",
    "    \n",
    "    pred_box_conf = tf.sigmoid(y_pred[..., 4])  ## confidence score\n",
    "    \n",
    "    pred_box_class = y_pred[..., 5:]   ## class probabilities\n",
    "    \n",
    "    ## IoU scores\n",
    "    \n",
    "    true_box_xy = y_true[..., 0:2]  \n",
    "    \n",
    "    true_box_wh = y_true[..., 2:4]  \n",
    "    \n",
    "    true_wh_half = true_box_wh / 2.\n",
    "    true_mins = true_box_xy - true_wh_half\n",
    "    true_maxes = true_box_xy + true_wh_half\n",
    "    \n",
    "    pred_wh_half = pred_box_wh / 2.\n",
    "    pred_mins = pred_box_xy - pred_wh_half\n",
    "    pred_maxes = pred_box_xy + pred_wh_half\n",
    "    \n",
    "    intersect_mins = tf.maximum(pred_mins, true_mins)\n",
    "    intersect_maxes = tf.minimum(pred_maxes, true_maxes)\n",
    "    intersect_wh = tf.maximum(intersect_maxes - intersect_mins, 0.)\n",
    "    intersect_areas = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
    "    \n",
    "    true_areas = true_box_wh[..., 0] * true_box_wh[..., 1]\n",
    "    pred_areas = pred_box_wh[..., 0] * pred_box_wh[..., 1]\n",
    "\n",
    "    union_areas = pred_areas + true_areas - intersect_areas\n",
    "    iou_scores = tf.truediv(intersect_areas, union_areas)\n",
    "    \n",
    "    true_box_conf = iou_scores * y_true[..., 4]\n",
    "    \n",
    "    true_box_class = tf.argmax(y_true[..., 5:], -1)\n",
    "    \n",
    "    ## Determine the masks\n",
    "    \n",
    "    coord_mask = tf.expand_dims(y_true[..., 4], axis=-1) * COORD_SCALE   ## coordinate mask\n",
    "\n",
    "    ## confidence mask: penalize predictors + penalize boxes with low IOU\n",
    "    # NMS - penalize the confidence of the boxes, which have IOU with some ground truth box < 0.6\n",
    "    true_xy = true_boxes[..., 0:2]\n",
    "    true_wh = true_boxes[..., 2:4]\n",
    "    \n",
    "    true_wh_half = true_wh / 2.\n",
    "    true_mins = true_xy - true_wh_half\n",
    "    true_maxes = true_xy + true_wh_half\n",
    "    \n",
    "    pred_xy = tf.expand_dims(pred_box_xy, 4)\n",
    "    pred_wh = tf.expand_dims(pred_box_wh, 4)\n",
    "    \n",
    "    pred_wh_half = pred_wh / 2.\n",
    "    pred_mins = pred_xy - pred_wh_half\n",
    "    pred_maxes = pred_xy + pred_wh_half\n",
    "    \n",
    "    intersect_mins = tf.maximum(pred_mins, true_mins)\n",
    "    intersect_maxes = tf.minimum(pred_maxes, true_maxes)\n",
    "    intersect_wh = tf.maximum(intersect_maxes - intersect_mins, 0.)\n",
    "    intersect_areas = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
    "    \n",
    "    true_areas = true_wh[..., 0] * true_wh[..., 1]\n",
    "    pred_areas = pred_wh[..., 0] * pred_wh[..., 1]\n",
    "\n",
    "    union_areas = pred_areas + true_areas - intersect_areas\n",
    "    iou_scores = tf.truediv(intersect_areas, union_areas)\n",
    "\n",
    "    best_ious = tf.reduce_max(iou_scores, axis=4)\n",
    "    conf_mask = conf_mask + tf.to_float(best_ious < 0.6) * (1 - y_true[..., 4]) * NO_OBJECT_SCALE\n",
    "    \n",
    "    # penalize the confidence of the boxes, which are responsible for corresponding ground truth box\n",
    "    conf_mask = conf_mask + y_true[..., 4] * OBJECT_SCALE\n",
    "    \n",
    "    ### class mask: position of the ground truth boxes (the predictors)\n",
    "    class_mask = y_true[..., 4] * tf.gather(CLASS_WEIGHTS, true_box_class) * CLASS_SCALE       \n",
    "    \n",
    "    ## Total loss\n",
    "    nb_coord_box = tf.reduce_sum(tf.to_float(coord_mask > 0.0))\n",
    "    nb_conf_box = tf.reduce_sum(tf.to_float(conf_mask > 0.0))\n",
    "    nb_class_box = tf.reduce_sum(tf.to_float(class_mask > 0.0))\n",
    "    \n",
    "    loss_xy = tf.reduce_sum(tf.square(true_box_xy - pred_box_xy) * coord_mask) / (nb_coord_box + 1e-6) / 2.\n",
    "    loss_wh = tf.reduce_sum(tf.square(true_box_wh - pred_box_wh) * coord_mask) / (nb_coord_box + 1e-6) / 2.\n",
    "    loss_conf = tf.reduce_sum(tf.square(true_box_conf - pred_box_conf) * conf_mask) / (nb_conf_box + 1e-6) / 2.\n",
    "    loss_class = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=true_box_class, logits=pred_box_class)\n",
    "    loss_class = tf.reduce_sum(loss_class * class_mask) / (nb_class_box + 1e-6)\n",
    "    \n",
    "    loss = loss_xy + loss_wh + loss_conf + loss_class\n",
    "    \n",
    "    nb_true_box = tf.reduce_sum(y_true[..., 4])\n",
    "    nb_pred_box = tf.reduce_sum(tf.to_float(true_box_conf > 0.5) * tf.to_float(pred_box_conf > 0.3))\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0a75aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch = BatchGenerator(preprocessed_images, preprocessed_labels, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefd1c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', \n",
    "                           min_delta=0.001, \n",
    "                           patience=3, \n",
    "                           mode='min', \n",
    "                           verbose=1)\n",
    "\n",
    "checkpoint = ModelCheckpoint('weights_coco.h5', \n",
    "                             monitor='val_loss', \n",
    "                             verbose=1, \n",
    "                             save_best_only=True, \n",
    "                             mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0ef61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6156d653",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=custom_loss, optimizer=optimizer)\n",
    "\n",
    "model.fit_generator(generator        = train_batch, \n",
    "                    steps_per_epoch  = len(train_batch), \n",
    "                    epochs           = 100, \n",
    "                    verbose          = 1,\n",
    "                    validation_data  = valid_batch,\n",
    "                    validation_steps = len(valid_batch),\n",
    "                    callbacks        = [early_stop, checkpoint, tensorboard], \n",
    "                    max_queue_size   = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57ba413",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
